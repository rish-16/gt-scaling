import json, math
import numpy as np
import matplotlib.pyplot as plt
import matplotlib

font = {'family' : 'normal',
        'size'   : 17}

matplotlib.rc('font', **font)
matplotlib.rc('legend', **{"loc": "upper left"})

# ALL TIMINGS ONLY HAVE Atom+LapPE encoders
transformer_inferences1 = {
    11: 0.02067875862121582,
    14: 0.020749807357788086,
    15: 0.021695852279663086,
    16: 0.02062249183654785,
    17: 0.020987272262573242,
    18: 0.02117633819580078,
    19: 0.020975589752197266,
    20: 0.02118372917175293,
    21: 0.020821809768676758,
    22: 0.02127695083618164,
    23: 0.021240711212158203,
    24: 0.02096867561340332,
    25: 0.020880460739135742,
    # 26: 0.8846487998962402,
    27: 0.021274566650390625,
    28: 0.020786046981811523,
    29: 0.02146291732788086,
    30: 0.021954774856567383,
    31: 0.02132868766784668,
    32: 0.024900197982788086,
    34: 0.021844863891601562,
    35: 0.021658897399902344
}

transformer_inferences2 = {
    11: 0.02112102508544922,
    14: 0.021014928817749023,
    15: 0.021787405014038086,
    16: 0.021280288696289062,
    17: 0.021193742752075195,
    18: 0.021284818649291992,
    19: 0.021143674850463867,
    20: 0.02134251594543457,
    21: 0.0211181640625,
    22: 0.021381378173828125,
    23: 0.021434307098388672,
    24: 0.02116107940673828,
    25: 0.020958423614501953,
    # 26: 0.8838410377502441,
    27: 0.021106958389282227,
    28: 0.021326303482055664,
    29: 0.021471738815307617,
    30: 0.021935462951660156,
    31: 0.021197080612182617,
    32: 0.021677732467651367,
    34: 0.021886110305786133,
    35: 0.021236658096313477
}

transformer_inferences3 = {
    11: 0.020832061767578125,
    14: 0.020476341247558594,
    15: 0.021212100982666016,
    16: 0.020886659622192383,
    17: 0.02092885971069336,
    18: 0.020692110061645508,
    19: 0.020605087280273438,
    20: 0.02079296112060547,
    21: 0.02073049545288086,
    22: 0.02080368995666504,
    23: 0.020972251892089844,
    24: 0.02043628692626953,
    25: 0.020259857177734375,
    # 26: 0.8801307678222656,
    27: 0.020556926727294922,
    28: 0.0203244686126709,
    29: 0.020797252655029297,
    30: 0.021548986434936523,
    31: 0.02074885368347168,
    32: 0.020970821380615234,
    34: 0.021326065063476562,
    35: 0.02493572235107422
}

performer_inferences1 = {
    11: 0.05425095558166504,
    14: 0.057489871978759766,
    15: 0.06299090385437012,
    16: 0.061998844146728516,
    17: 0.058785200119018555,
    18: 0.05951118469238281,
    19: 0.060259342193603516,
    20: 0.06083512306213379,
    21: 0.061995506286621094,
    22: 0.06556129455566406,
    23: 0.06431150436401367,
    24: 0.06595897674560547,
    25: 0.06916260719299316,
    # 26: 0.9413666725158691,
    27: 0.06744766235351562,
    28: 0.0676581859588623,
    29: 0.06867694854736328,
    30: 0.07247471809387207,
    31: 0.07038736343383789,
    32: 0.0711662769317627,
    34: 0.07294631004333496,
    35: 0.0738368034362793
}

performer_inferences2 = {
    11: 0.038376808166503906,
    14: 0.04010915756225586,
    15: 0.043183326721191406,
    16: 0.04273843765258789,
    17: 0.04298973083496094,
    18: 0.041345834732055664,
    19: 0.041828155517578125,
    20: 0.04259371757507324,
    21: 0.04589486122131348,
    22: 0.044762372970581055,
    23: 0.04509472846984863,
    24: 0.04561138153076172,
    25: 0.0443265438079834,
    # 26: 0.9135854244232178,
    27: 0.0469818115234375,
    28: 0.04565143585205078,
    29: 0.04680204391479492,
    30: 0.04868721961975098,
    31: 0.047508955001831055,
    32: 0.047463178634643555,
    34: 0.04899191856384277,
    35: 0.04887890815734863
}

performer_inferences3 = {
    11: 0.034475088119506836,
    14: 0.03629660606384277,
    15: 0.04204273223876953,
    16: 0.03862452507019043,
    17: 0.038784027099609375,
    18: 0.037445068359375,
    19: 0.03786182403564453,
    20: 0.03948235511779785,
    21: 0.03868556022644043,
    22: 0.04088902473449707,
    23: 0.04117703437805176,
    24: 0.04162955284118652,
    25: 0.04079389572143555,
    # 26: 0.8930609226226807,
    27: 0.04292607307434082,
    28: 0.04205584526062012,
    29: 0.042542457580566406,
    30: 0.044569969177246094,
    31: 0.043504953384399414,
    32: 0.04363131523132324,
    34: 0.04486203193664551,
    35: 0.045046329498291016
}

bigbird_inferences1 = {
    11: 0.05367469787597656,
    14: 0.05936384201049805,
    15: 0.05901026725769043,
    16: 0.06021690368652344,
    17: 0.06018972396850586,
    18: 0.06001114845275879,
    19: 0.06149029731750488,
    20: 0.06568598747253418,
    21: 0.06094479560852051,
    22: 0.0625910758972168,
    23: 0.06236600875854492,
    24: 0.06207132339477539,
    25: 0.07027387619018555,
    # 26: 0.9317469596862793,
    27: 0.06965184211730957,
    28: 0.07357621192932129,
    29: 0.07365083694458008,
    30: 0.07392144203186035,
    31: 0.07617020606994629,
    32: 0.0753018856048584,
    34: 0.07308411598205566,
    35: 0.06765890121459961
}

bigbird_inferences2 = {
    11: 0.05639791488647461,
    14: 0.06083059310913086,
    15: 0.06071639060974121,
    16: 0.06647658348083496,
    17: 0.06320309638977051,
    18: 0.062040090560913086,
    19: 0.06328916549682617,
    20: 0.06309032440185547,
    21: 0.06289434432983398,
    22: 0.06479287147521973,
    23: 0.06408548355102539,
    24: 0.06393742561340332,
    25: 0.07137680053710938,
    # 26: 0.933978796005249,
    27: 0.07086443901062012,
    28: 0.07412862777709961,
    29: 0.07461905479431152,
    30: 0.07429981231689453,
    31: 0.07667899131774902,
    32: 0.07594156265258789,
    34: 0.06975269317626953,
    35: 0.06899189949035645
}

bigbird_inferences3 = {
    11: 0.05557584762573242,
    14: 0.061585426330566406,
    15: 0.060689449310302734,
    16: 0.0663292407989502,
    17: 0.06670308113098145,
    18: 0.062322378158569336,
    19: 0.06315779685974121,
    20: 0.06377649307250977,
    21: 0.06272625923156738,
    22: 0.06476283073425293,
    23: 0.06461858749389648,
    24: 0.06403851509094238,
    25: 0.07175946235656738,
    # 26: 0.9396910667419434,
    27: 0.070587158203125,
    28: 0.07462215423583984,
    29: 0.07493758201599121,
    30: 0.07473611831665039,
    31: 0.07722163200378418,
    32: 0.07715392112731934,
    34: 0.06980633735656738,
    35: 0.06956601142883301
}

transformer_x = list(transformer_inferences1.keys())
transformer_y1 = list(transformer_inferences1.values())
transformer_y2 = list(transformer_inferences2.values())
transformer_y3 = list(transformer_inferences3.values())

transformer_y = []
for y1, y2, y3 in zip(transformer_y1, transformer_y2, transformer_y3):
    transformer_y.append([y1, y2, y3])
transformer_y = np.asarray(transformer_y)
transformer_y_avg = transformer_y.mean(axis=1)
transformer_y_std = transformer_y.std(axis=1)

# print (transformer_y_avg)
# print (sum([0.02037954330444336, 0.020636796951293945, 0.020218849182128906]) / 3)
# print (transformer_y_avg[0])

performer_x = list(performer_inferences1.keys())
performer_y1 = list(performer_inferences1.values())
performer_y2 = list(performer_inferences2.values())
performer_y3 = list(performer_inferences3.values())

performer_y = []
for y1, y2, y3 in zip(performer_y1, performer_y2, performer_y3):
    performer_y.append([y1, y2, y3])
performer_y = np.asarray(performer_y)
performer_y_avg = performer_y.mean(axis=1)
performer_y_std = performer_y.std(axis=1)

bigbird_x = list(bigbird_inferences1.keys())
bigbird_y1 = list(bigbird_inferences1.values())
bigbird_y2 = list(bigbird_inferences2.values())
bigbird_y3 = list(bigbird_inferences3.values()) 

bigbird_y = []
for y1, y2, y3 in zip(bigbird_y1, bigbird_y2, bigbird_y3):
    bigbird_y.append([y1, y2, y3])
bigbird_y = np.asarray(bigbird_y)
bigbird_y_avg = bigbird_y.mean(axis=1)
bigbird_y_std = bigbird_y.std(axis=1)

fig = plt.figure()
ax = fig.add_subplot(111)

# xint = range(min(transformer_x), math.ceil(max(transformer_x))+1)
# matplotlib.pyplot.xticks(xint)

plt.plot(transformer_x, transformer_y_avg, color="red", label="GPS-Transformer-M", markersize=10)
plt.fill_between(
    transformer_x,
    np.asarray(transformer_y_avg) - np.asarray(transformer_y_std), 
    np.asarray(transformer_y_avg) + np.asarray(transformer_y_std),
    alpha=0.3,
    color="red"
)

plt.plot(performer_x, performer_y_avg, color="blue", label="GPS-Performer-M", markersize=10)
plt.fill_between(
    performer_x,
    np.asarray(performer_y_avg) - np.asarray(performer_y_std),
    np.asarray(performer_y_avg) + np.asarray(performer_y_std),
    alpha=0.3,
    color="blue"
)

plt.plot(bigbird_x, bigbird_y_avg, color="green", label="GPS-BigBird-M")
plt.fill_between(
    bigbird_x,
    np.asarray(bigbird_y_avg) - np.asarray(bigbird_y_std),
    np.asarray(bigbird_y_avg) + np.asarray(bigbird_y_std),
    alpha=0.3,
    color="green"
)

plt.xlabel("Number of atoms")
plt.ylabel("Batch Inference Runtime (B = 128) / sec")
plt.legend()
plt.grid(linestyle="dashed")
plt.show()

fig.savefig("figures/scaling/zinc_variant_scaling_graph_size.pdf", dpi=400, bbox_inches='tight')